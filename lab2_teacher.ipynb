{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of inverted index\n",
    "#1.1\n",
    "from pprint import pprint\n",
    "class inverted_index:\n",
    "\n",
    "     def __init__(self, name):\n",
    "        self.name = name \n",
    "        self.document_count = 0\n",
    "        self.dictionary = {}\n",
    "        self.doc_to_pair = {}\n",
    "    \n",
    "     def add_to_index(self, filename):\n",
    "        document = open(filename, 'r').read()\n",
    "        words = nltk.word_tokenize(document)\n",
    "        data_analysis = nltk.FreqDist(words)\n",
    "        #pprint(data_analysis)\n",
    "        for k, v in data_analysis.items():\n",
    "            if k in self.dictionary:\n",
    "                self.dictionary[k].append((self.document_count,v))\n",
    "                self.dictionary[k][0] += 1\n",
    "            else:\n",
    "                self.dictionary[k] = [1,(self.document_count,v)]\n",
    "                \n",
    "        self.doc_to_pair[self.document_count] = (len(words), len(data_analysis))\n",
    "        self.document_count += 1\n",
    "        \n",
    "        #document identifiers to pairs (#tokens, #terms) ?\n",
    "        \n",
    "    \n",
    "        \n",
    "     def clear(self):\n",
    "        self.dictionary = {\"document_count\": 0,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (362, 204), 1: (340, 199)}\n",
      "{'&': [2, (0, 1), (1, 1)],\n",
      " ',': [2, (0, 10), (1, 9)],\n",
      " '.': [2, (0, 11), (1, 10)],\n",
      " '3': [2, (0, 3), (1, 2)],\n",
      " ':': [2, (0, 2), (1, 2)],\n",
      " '>': [2, (0, 3), (1, 3)],\n",
      " 'Analytics.': [2, (0, 1), (1, 1)],\n",
      " 'As': [2, (0, 1), (1, 1)],\n",
      " 'At': [2, (0, 1), (1, 1)],\n",
      " 'Autopilot': [2, (0, 1), (1, 1)],\n",
      " 'BLINDED': [2, (0, 1), (1, 1)],\n",
      " 'CEO': [2, (0, 1), (1, 1)],\n",
      " 'Camera': [2, (0, 1), (1, 1)],\n",
      " 'Controls': [2, (0, 1), (1, 1)],\n",
      " 'DARK': [2, (0, 1), (1, 1)],\n",
      " 'DATA': [2, (0, 1), (1, 1)],\n",
      " 'EYES_CLOSED': [2, (0, 1), (1, 1)],\n",
      " 'EYES_DOWN': [2, (0, 1), (1, 1)],\n",
      " 'EYES_NOMINAL': [2, (0, 1), (1, 1)],\n",
      " 'EYES_UP': [2, (0, 1), (1, 1)],\n",
      " 'Elon': [2, (0, 1), (1, 1)],\n",
      " 'For': [2, (0, 1), (1, 1)],\n",
      " 'GM': [2, (0, 1), (1, 1)],\n",
      " 'HEAD_DOWN': [2, (0, 1), (1, 1)],\n",
      " 'HEAD_TRUNC': [2, (0, 1), (1, 1)],\n",
      " 'Help': [2, (0, 1), (1, 1)],\n",
      " 'If': [2, (0, 1), (1, 1)],\n",
      " 'It': [2, (0, 1), (1, 1)],\n",
      " 'LOOKING_LEFT': [2, (0, 1), (1, 1)],\n",
      " 'LOOKING_RIGHT': [2, (0, 1), (1, 1)],\n",
      " 'Model': [2, (0, 3), (1, 2)],\n",
      " 'Musk': [2, (0, 1), (1, 1)],\n",
      " 'Now': [2, (0, 1), (1, 1)],\n",
      " 'PHONE_USE': [2, (0, 1), (1, 1)],\n",
      " 'SUNGLASSES_EYES_LIKELY_NOMINAL': [2, (0, 1), (1, 1)],\n",
      " 'SUNGLASSES_LIKELY_EYES_DOWN': [2, (0, 1), (1, 1)],\n",
      " 'Safety': [2, (0, 1), (1, 1)],\n",
      " 'Security': [2, (0, 1), (1, 1)],\n",
      " 'Several': [2, (0, 1), (1, 1)],\n",
      " 'Sharing': [2, (0, 1), (1, 1)],\n",
      " 'Supercruise': [2, (0, 1), (1, 1)],\n",
      " 'Tesla': [2, (0, 10), (1, 9)],\n",
      " 'The': [2, (0, 1), (1, 1)],\n",
      " 'This': [2, (0, 1), (1, 1)],\n",
      " 'When': [1, (0, 1)],\n",
      " 'Y': [2, (0, 1), (1, 1)],\n",
      " 'a': [2, (0, 3), (1, 2)],\n",
      " 'above': [2, (0, 1), (1, 1)],\n",
      " 'activated': [2, (0, 1), (1, 1)],\n",
      " 'active': [2, (0, 3), (1, 3)],\n",
      " 'actively': [2, (0, 1), (1, 1)],\n",
      " 'adjust': [2, (0, 1), (1, 1)],\n",
      " 'allow': [2, (0, 1), (1, 1)],\n",
      " 'almost': [2, (0, 1), (1, 1)],\n",
      " 'and': [2, (0, 7), (1, 7)],\n",
      " 'applied': [2, (0, 1), (1, 1)],\n",
      " 'are': [2, (0, 3), (1, 3)],\n",
      " 'at': [2, (0, 1), (1, 1)],\n",
      " 'attached': [2, (0, 1), (1, 1)],\n",
      " 'attention': [2, (0, 1), (1, 1)],\n",
      " 'automaker': [2, (0, 3), (1, 3)],\n",
      " 'automatically': [2, (0, 2), (1, 2)],\n",
      " 'be': [2, (0, 3), (1, 3)],\n",
      " 'being': [2, (0, 3), (1, 3)],\n",
      " 'believe': [2, (0, 1), (1, 1)],\n",
      " 'built-in': [2, (0, 1), (1, 1)],\n",
      " 'by': [2, (0, 2), (1, 2)],\n",
      " 'cabin': [2, (0, 1), (1, 1)],\n",
      " 'cabin-facing': [2, (0, 2), (1, 1)],\n",
      " 'camera': [2, (0, 8), (1, 7)],\n",
      " 'cameras': [2, (0, 1), (1, 1)],\n",
      " 'can': [2, (0, 1), (1, 1)],\n",
      " 'capture': [2, (0, 1), (1, 1)],\n",
      " 'cars': [2, (0, 1), (1, 1)],\n",
      " 'clip': [2, (0, 1), (1, 1)],\n",
      " 'clips': [2, (0, 1), (1, 1)],\n",
      " 'collecting': [2, (0, 1), (1, 1)],\n",
      " 'collision': [2, (0, 1), (1, 1)],\n",
      " 'company': [2, (0, 1), (1, 1)],\n",
      " 'consent': [2, (0, 1), (1, 1)],\n",
      " 'continue': [2, (0, 1), (1, 1)],\n",
      " 'could': [2, (0, 1), (1, 1)],\n",
      " 'data': [2, (0, 3), (1, 3)],\n",
      " 'detect': [2, (0, 1), (1, 1)],\n",
      " 'detecting': [2, (0, 1), (1, 1)],\n",
      " 'develop': [2, (0, 2), (1, 2)],\n",
      " 'discovered': [2, (0, 1), (1, 1)],\n",
      " 'driven': [2, (0, 1), (1, 1)],\n",
      " 'driver': [2, (0, 2), (1, 2)],\n",
      " 'driver-assist': [2, (0, 1), (1, 1)],\n",
      " 'driver-facing': [2, (0, 1), (1, 1)],\n",
      " 'drivers': [2, (0, 4), (1, 4)],\n",
      " 'earlier': [2, (0, 1), (1, 1)],\n",
      " 'enable': [2, (0, 1), (1, 1)],\n",
      " 'enabled': [2, (0, 1), (1, 1)],\n",
      " 'engaged': [2, (0, 1), (1, 1)],\n",
      " 'engineers': [2, (0, 1), (1, 1)],\n",
      " 'enhancements': [2, (0, 1), (1, 1)],\n",
      " 'equipped': [1, (0, 1)],\n",
      " 'event': [2, (0, 1), (1, 1)],\n",
      " 'events': [2, (0, 1), (1, 1)],\n",
      " 'eventually': [2, (0, 1), (1, 1)],\n",
      " 'existing': [2, (0, 1), (1, 1)],\n",
      " 'feature': [2, (0, 1), (1, 1)],\n",
      " 'features': [2, (0, 4), (1, 4)],\n",
      " 'first': [2, (0, 1), (1, 1)],\n",
      " 'for': [2, (0, 3), (1, 3)],\n",
      " 'from': [2, (0, 3), (1, 3)],\n",
      " 'future': [2, (0, 3), (1, 3)],\n",
      " 'green': [2, (0, 1), (1, 1)],\n",
      " 'hacker': [2, (0, 1), (1, 1)],\n",
      " 'has': [2, (0, 1), (1, 1)],\n",
      " 'help': [2, (0, 1), (1, 1)],\n",
      " 'if': [2, (0, 1), (1, 1)],\n",
      " 'images': [2, (0, 2), (1, 2)],\n",
      " 'improve': [2, (0, 1), (1, 1)],\n",
      " 'in': [2, (0, 5), (1, 4)],\n",
      " 'instead': [2, (0, 1), (1, 1)],\n",
      " 'is': [2, (0, 5), (1, 5)],\n",
      " 'it': [2, (0, 4), (1, 3)],\n",
      " 'just': [2, (0, 1), (1, 1)],\n",
      " 'known': [2, (0, 1), (1, 1)],\n",
      " 'launched': [1, (0, 1)],\n",
      " 'led': [2, (0, 1), (1, 1)],\n",
      " 'like': [2, (0, 1), (1, 1)],\n",
      " 'located': [1, (0, 1)],\n",
      " 'looking': [2, (0, 1), (1, 1)],\n",
      " 'make': [2, (0, 1), (1, 1)],\n",
      " 'many': [2, (0, 1), (1, 1)],\n",
      " 'mirror': [2, (0, 2), (1, 1)],\n",
      " 'monitor': [2, (0, 1), (1, 1)],\n",
      " 'monitoring': [2, (0, 2), (1, 2)],\n",
      " 'network': [2, (0, 1), (1, 1)],\n",
      " 'not': [2, (0, 2), (1, 2)],\n",
      " 'on': [2, (0, 2), (1, 2)],\n",
      " 'ones': [2, (0, 1), (1, 1)],\n",
      " 'only': [2, (0, 2), (1, 2)],\n",
      " 'or': [2, (0, 1), (1, 1)],\n",
      " 'other': [2, (0, 1), (1, 1)],\n",
      " 'people': [2, (0, 1), (1, 1)],\n",
      " 'preferences': [2, (0, 1), (1, 1)],\n",
      " 'prevent': [2, (0, 1), (1, 1)],\n",
      " 'prior': [2, (0, 1), (1, 1)],\n",
      " 'purposes': [2, (0, 1), (1, 1)],\n",
      " 'rearview': [2, (0, 2), (1, 1)],\n",
      " 'releasing': [2, (0, 1), (1, 1)],\n",
      " 'research': [2, (0, 1), (1, 1)],\n",
      " 'revealing': [2, (0, 1), (1, 1)],\n",
      " 'road': [2, (0, 1), (1, 1)],\n",
      " 'robotaxi': [2, (0, 1), (1, 1)],\n",
      " 's': [2, (0, 4), (1, 4)],\n",
      " 'safer': [2, (0, 1), (1, 1)],\n",
      " 'safety': [2, (0, 2), (1, 2)],\n",
      " 'said': [2, (0, 2), (1, 2)],\n",
      " 'says': [2, (0, 1), (1, 1)],\n",
      " 'self-driving': [2, (0, 1), (1, 1)],\n",
      " 'sharing': [2, (0, 2), (1, 2)],\n",
      " 'short': [2, (0, 1), (1, 1)],\n",
      " 'software': [2, (0, 1), (1, 1)],\n",
      " 'some': [2, (0, 1), (1, 1)],\n",
      " 'specific': [2, (0, 1), (1, 1)],\n",
      " 'standard': [1, (0, 1)],\n",
      " 'started': [2, (0, 1), (1, 1)],\n",
      " 'sure': [2, (0, 1), (1, 1)],\n",
      " 'systems': [2, (0, 1), (1, 1)],\n",
      " 't': [2, (0, 1), (1, 1)],\n",
      " 'tapping': [2, (0, 1), (1, 1)],\n",
      " 'that': [2, (0, 4), (1, 4)],\n",
      " 'the': [2, (0, 22), (1, 19)],\n",
      " 'they': [2, (0, 1), (1, 1)],\n",
      " 'this': [2, (0, 1), (1, 1)],\n",
      " 'time': [2, (0, 2), (1, 2)],\n",
      " 'to': [2, (0, 12), (1, 12)],\n",
      " 'torque': [2, (0, 1), (1, 1)],\n",
      " 'trying': [2, (0, 1), (1, 1)],\n",
      " 'until': [2, (0, 1), (1, 1)],\n",
      " 'upcoming': [2, (0, 1), (1, 1)],\n",
      " 'update': [2, (0, 1), (1, 1)],\n",
      " 'used': [2, (0, 3), (1, 3)],\n",
      " 'uses': [2, (0, 1), (1, 1)],\n",
      " 'using': [2, (0, 2), (1, 2)],\n",
      " 'usual': [2, (0, 1), (1, 1)],\n",
      " 'vandalizing': [2, (0, 1), (1, 1)],\n",
      " 'vehicle': [2, (0, 2), (1, 1)],\n",
      " 'vehicles': [2, (0, 2), (1, 2)],\n",
      " 'video': [2, (0, 1), (1, 1)],\n",
      " 'was': [2, (0, 1), (1, 1)],\n",
      " 'wasn': [2, (0, 1), (1, 1)],\n",
      " 'what': [2, (0, 1), (1, 1)],\n",
      " 'wheel': [2, (0, 1), (1, 1)],\n",
      " 'when': [2, (0, 3), (1, 3)],\n",
      " 'will': [2, (0, 2), (1, 2)],\n",
      " 'with': [2, (0, 3), (1, 2)],\n",
      " 'without': [2, (0, 1), (1, 1)],\n",
      " 'working': [2, (0, 1), (1, 1)],\n",
      " 'would': [2, (0, 2), (1, 2)],\n",
      " 'year': [2, (0, 1), (1, 1)],\n",
      " 'years': [2, (0, 1), (1, 1)],\n",
      " 'you': [2, (0, 2), (1, 2)],\n",
      " 'your': [2, (0, 2), (1, 2)],\n",
      " '‘': [2, (0, 2), (1, 2)],\n",
      " '’': [2, (0, 6), (1, 6)],\n",
      " '“': [2, (0, 1), (1, 1)],\n",
      " '”': [2, (0, 1), (1, 1)]}\n"
     ]
    }
   ],
   "source": [
    "#testing 1.1\n",
    "i_index = inverted_index('Random files')\n",
    "i_index.add_to_index('filename.txt') \n",
    "i_index.add_to_index('filename1.txt') \n",
    "\n",
    "pprint(i_index.doc_to_pair)\n",
    "pprint(i_index.dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[362, 340]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.2\n",
    "#distribution of terms per document?\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "x = []\n",
    "for i in range(i_index.document_count):\n",
    "    x.append(i_index.doc_to_pair[i][0])\n",
    "print(x)\n",
    "#x = [value1, value2, value3] \n",
    "plt.hist(x , bins = 3) \n",
    "plt.show()\n",
    "#this shows the distribution of documents in 4 bins based on their total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.3\n",
    "import math\n",
    "\"\"\"give string term => t ; returns inverse document frequency\"\"\"\n",
    "def idf(t,i_index):\n",
    "    df = len(i_index.dictionary[t])-1\n",
    "    idf = math.log(i_index.document_count / df)\n",
    "    return idf\n",
    "idf('When', i_index)\n",
    "# in this case, as the term occurs in all documents (not much rarity), the idf is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query:equipped && ,\n",
      "searching for equipped && , in Random files...\n",
      "document 0: True && True\n",
      "True and True\n",
      "document 1: False && True\n",
      "False and True\n",
      "Its present in the following documents: [0]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#Boolean model\n",
    "\n",
    "#In case you are using a standar .py file you can use this to get the query\n",
    "#import sys\n",
    "#query = sys.argv[1]\n",
    "query = input(\"Insert your query:\") \n",
    "\n",
    "print('searching for '+ query +' in '+ i_index.name+'...')\n",
    "\n",
    "\n",
    "\n",
    "aux_vect = query.split(' ')\n",
    "if(len(aux_vect) == 1):\n",
    "    result = [a_tuple[0] for a_tuple in i_index.dictionary[query][1:]]\n",
    "else: # if it is an expression\n",
    "    result = []\n",
    "    for i in range(i_index.document_count):\n",
    "        sq = query.split(' ')\n",
    "        for j in range(len(sq)):\n",
    "            #print(sq[j])\n",
    "            try:\n",
    "                if sq[j] not in ['&&','||','!'] :\n",
    "                    doc_vect = [a_tuple[0] for a_tuple in i_index.dictionary[str(sq[j])][1:]]\n",
    "                    test = i in doc_vect\n",
    "                    sq[j] = test\n",
    "            except:\n",
    "                sq[j] = False\n",
    "        #list to string query:\n",
    "        query_done = ' '.join(map(str, sq))\n",
    "        print(\"document \"+str(i)+\": \"+query_done)\n",
    "        qd = query_done.replace('&&', 'and').replace('||', 'or').replace('!', 'not ')\n",
    "        print(qd)\n",
    "        if eval(qd):\n",
    "            result.append(i)\n",
    "\n",
    "print('Its present in the following documents: '+ str(result))\n",
    "# equipped && , <<= this is an example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 2)]\n",
      "[(0, 1)]\n",
      "[(0, 10), (1, 9)]\n",
      "{0: 0.6931471805599453, 1: 0.0}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Q is the term list\n",
    "Q = ['driver','equipped',',']\n",
    "\n",
    "A = {}\n",
    "\n",
    "for t in Q:\n",
    "    I_t = i_index.dictionary[t][1:]\n",
    "    print(I_t)\n",
    "    idf_t = idf(t,i_index)\n",
    "    current_doc = [a_tuple[1] for a_tuple in I_t]\n",
    "    for pair in I_t:\n",
    "        if pair[0] not in A.keys():\n",
    "            A[pair[0]] = 0\n",
    "        A[pair[0]] = A[pair[0]] + pair[1] * idf_t\n",
    "\n",
    "pprint(A)\n",
    "            \n",
    "# this would be more interesting with more files with less similar contents\n",
    "# but as you can see,given that 'equipped' is only in one of the documents, \n",
    "# the document that contains it has a higher similarity, \n",
    "# in contrast to the document that has words present in all documents, hence 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Pen and Paper\n",
    "\n",
    "Começamos por calcular o IDF para os dez diferentes termos no vocabulário que é usado nos documentos. A cada termo do vocabulário atribuímos também um identificador, o qual irá corresponder a uma dada dimensão nos vectores resultantes da representação vectorial dos documentos:\n",
    "\n",
    "01: IDF(01) = IDF(shipment) = $\\log(4/2)$ = 0.3 \n",
    "\n",
    "02: IDF(02) = IDF(of) = $\\log(4/3)$ = 0.1 \n",
    "\n",
    "03: IDF(03) = IDF(gold) = $\\log(4/1)$ = 0.6 \n",
    "\n",
    "04: IDF(04) = IDF(damaged) = $\\log(4/2)$ = 0.3\n",
    "\n",
    "05: IDF(05) = IDF(in) = $\\log(4/4)$ = 0.0\n",
    "\n",
    "06: IDF(06) = IDF(fire) = $\\log(4/2)$ = 0.3\n",
    "\n",
    "07: IDF(07) = IDF(delivery) = $\\log(4/1)$ = 0.6\n",
    "\n",
    "08: IDF(08) = IDF(silver) = $\\log(4/2)$ = 0.3\n",
    "\n",
    "09: IDF(09) = IDF(arrived) = $\\log(4/2)$ = 0.3\n",
    "\n",
    "10: IDF(10) = IDF(truck) = $\\log(4/3)$ = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, cada um dos documentos é representado por um vector com dez dimensões, resultante de multiplicar o TF de cada um dos dez termos no documento, pelo respectivo IDF.\n",
    "\n",
    "1: $<$ 1 $\\times$ IDF(01) , 1 $\\times$ IDF(02) , 1 $\\times$ IDF(03) , 1 $\\times$ IDF(04) , 1 $\\times$ IDF(05) , 1 $\\times$ IDF(06) , 0 $\\times$ IDF(07) , 0 $\\times$ IDF(08) , 0 $\\times$ IDF(09) , 0 $\\times$ IDF(10) $>$\n",
    "\n",
    "\n",
    "\n",
    "2: $<$ 0 $\\times$ IDF(01) , 1 $\\times$ IDF(02) , 0 $\\times$ IDF(03) , 0 $\\times$ IDF(04) , 1 $\\times$ IDF(05) , 0 $\\times$ IDF(06) , 1 $\\times$ IDF(07) , 2 $\\times$ IDF(08) , 1 $\\times$ IDF(09) , 1 $\\times$ IDF(10) $>$\n",
    "\n",
    "\n",
    "3: $<$ 1 $\\times$ IDF(01) , 1 $\\times$ IDF(02) , 0 $\\times$ IDF(03) , 0 $\\times$ IDF(04) , 1 $\\times$ IDF(05) , 0 $\\times$ IDF(06) , 0 $\\times$ IDF(07) , 1 $\\times$ IDF(08) , 1 $\\times$ IDF(09) , 1 $\\times$ IDF(10) $>$\n",
    "\n",
    "\n",
    "4: $<$ 0 $\\times$ IDF(01) , 0 $\\times$ IDF(02) , 0 $\\times$ IDF(03) , 1 $\\times$ IDF(04) , 1 $\\times$ IDF(05) , 1 $\\times$ IDF(06) , 0 $\\times$ IDF(07) , 0 $\\times$ IDF(08) , 0 $\\times$ IDF(09) , 1 $\\times$ IDF(10) $>$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após os cálculos, ficaríamos com as seguintes representações para os documentos\n",
    "\n",
    "1: $<$ 0.3 , 0.1 , 0.6 , 0.3 , 0.0 , 0.3 , 0.0 , 0.0 , 0.0 , 0.0 $>$ ~~~~~~~~~~~~ 2: $<$ 0.0 , 0.1 , 0.0 , 0.0 , 0.0 , 0.0 , 0.6 , 0.6 , 0.3 , 0.1 $>$\n",
    "\n",
    "3: $<$ 0.3 , 0.1 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.3 , 0.3 , 0.1 $>$ ~~~~~~~~~~~~ 4: $<$ 0.0 , 0.0 , 0.0 , 0.3 , 0.0 , 0.3 , 0.0 , 0.0 , 0.0 , 0.1 $>$\n",
    "\n",
    "\n",
    "A representação vectorial para a consulta seria $<$ 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 1.0 , 0.0 , 1.0 $>$\n",
    "~\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O documento mais relevante para a consulta seria assim o número 2, pois seria este o que obteria o maior valor para a semelhança do cosseno entre uma representação para um documento, e a representação para a consulta. \n",
    "~\\\\\n",
    "\n",
    "Note-se que apenas as dimensões 8 e 10 dos vectores iriam contribuir para o valor da semelhança do cosseno, e note-se que o documento 2 é aquele que apresenta um valor mais alto na dimensão 8. A semelhança do cosseno entre dois vectores $\\mathbf{A}$ e $\\mathbf{B}$ é calculada de acordo com a seguinte equação:\n",
    "\n",
    "$\\text{similarity} = \\cos(\\theta) = {\\mathbf{A} \\cdot \\mathbf{B} \\over \\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} = \\frac{ \\sum\\limits_{i=1}^{n}{A_i  B_i} }{ \\sqrt{\\sum\\limits_{i=1}^{n}{A_i^2}}  \\sqrt{\\sum\\limits_{i=1}^{n}{B_i^2}} }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
